{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert RTF theatre play script to text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Amleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "# Open the RTF file for reading\n",
    "Name = False\n",
    "Text = False \n",
    "rtf_file_path = '/Users/hugo/Desktop/Projects/MSERT/scripts/not_processed/Amleth_notprocessed.rtf'\n",
    "with open(rtf_file_path, 'rb') as rtf_file:\n",
    "    # Use the striprtf library to convert RTF to plain text\n",
    "    rtf_text = rtf_file.read()\n",
    "    #convert bytes to string\n",
    "    rtf_text = rtf_text.decode('utf-8')\n",
    "\n",
    "    text_file_path = '/Users/hugo/Desktop/Projects/MSERT/scripts/processed/Amleth_processed.txt'\n",
    "    text_file = open(text_file_path, 'w')\n",
    "    idx = 0\n",
    "    #rtf_text = rtf_text.replace(\"b'{\\\\rtf1\\\\ansi\\\\ansicpg1252\\\\cocoartf2709\\n\\\\cocoatextscaling0\\\\cocoaplatform0{\\\\fonttbl\\\\f0\\\\fswiss\\\\fcharset0 Helvetica-Bold;\\\\f1\\\\fswiss\\\\fcharset0 Helvetica;\\\\f2\\\\froman\\\\fcharset0 Times-Bold;\\n\\\\f3\\\\froman\\\\fcharset0 Times-Roman;\\\\f4\\\\froman\\\\fcharset0 Times-Italic;}\\n{\\\\colortbl;\\\\red255\\\\green255\\\\blue255;\\\\red0\\\\green0\\\\blue0;\\\\red194\\\\green245\\\\blue244;\\\\red109\\\\green109\\\\blue109;\\n\\\\red0\\\\green0\\\\blue233;\\\\red255\\\\green255\\\\blue255;}\\n{\\\\*\\\\expandedcolortbl;;\\\\cssrgb\\\\c0\\\\c0\\\\c0;\\\\cssrgb\\\\c80000\\\\c96471\\\\c96471;\\\\cssrgb\\\\c50196\\\\c50196\\\\c50196;\\n\\\\cssrgb\\\\c0\\\\c0\\\\c93333;\\\\cssrgb\\\\c100000\\\\c100000\\\\c100000;}\\n\\\\paperw11900\\\\paperh16840\\\\margl1440\\\\margr1440\\\\vieww11520\\\\viewh8400\\\\viewkind0\\n\\\\deftab720\\n\\n\\\\itap1\\\\trowd \\\\taflags0 \\\\trgaph108\\\\trleft-108 \\\\trcbpat3 \\\\trwWidth15380\\\\trftsWidth3 \\\\trbrdrt\\\\brdrnil \\\\trbrdrl\\\\brdrnil \\\\trbrdrr\\\\brdrnil \\n\\\\clvertalc \\\\clshdrawnil \\\\clwWidth15260\\\\clftsWidth3 \\\\clmart10 \\\\clmarl10 \\\\clmarb10 \\\\clmarr10 \\\\clbrdrt\\\\brdrnil \\\\clbrdrl\\\\brdrnil \\\\clbrdrb\\\\brdrnil \\\\clbrdrr\\\\brdrnil \\\\clpadt20 \\\\clpadl20 \\\\clpadb20 \\\\clpadr20 \\\\gaph\\\\cellx8640\\n\\\\pard\\\\intbl\\\\itap1\\\\pardeftab720\\\\qc\\\\partightenfactor0\\n\\n\\\\f0\\\\b\\\\fs48 \\\\cf0 \\\\expnd0\\\\expndtw0\\\\kerning0\\n\\\\outl0\\\\strokewidth0 \\\\strokec2 The Tragedy of Hamlet, Prince of Denmark\\\\cell \\\\row\\n\\n\\\\itap1\\\\trowd \\\\taflags0 \\\\trgaph108\\\\trleft-108 \\\\trcbpat3 \\\\trwWidth15380\\\\trftsWidth3 \\\\trbrdrl\\\\brdrnil \\\\trbrdrt\\\\brdrnil \\\\trbrdrr\\\\brdrnil \\n\\\\clvertalc \\\\clshdrawnil \\\\clwWidth15260\\\\clftsWidth3 \\\\clmart10 \\\\clmarl10 \\\\clmarb10 \\\\clmarr10 \\\\clbrdrt\\\\brdrnil \\\\clbrdrl\\\\brdrnil \\\\clbrdrb\\\\brdrnil \\\\clbrdrr\\\\brdrnil \\\\clpadt20 \\\\clpadl20 \\\\clpadb20 \\\\clpadr20 \\\\gaph\\\\cellx8640\\n\\\\pard\\\\intbl\\\\itap1\\\\pardeftab720\\\\qc\\\\partightenfactor0\\n{\\\\field{\\\\*\\\\fldinst{HYPERLINK \"http://shakespeare.mit.edu/Shakespeare\"}}{\\\\fldrslt \\n\\\\f1\\\\b0\\\\fs24 \\\\cf5 \\\\ul \\\\ulc5 \\\\strokec5 Shakespeare homepage}}\\n\", '')\n",
    "    # Go throw the rtf_text (which is a string) and write each text line in a text file (if the text is between \\i and \\i0, add '**' at the beginning and end of the line)\n",
    "    text = rtf_text.split(\"\\n\")\n",
    "    for line in text:\n",
    "        \n",
    "        #TEXT\n",
    "        if Text == True : \n",
    "            if line == '' :\n",
    "                Text = False\n",
    "            else : \n",
    "                text_file.write(line.replace('\\\\', '')+'\\n')\n",
    "\n",
    "        if line[0:8] == \"\\\\f3\\\\b0 \\\\\":\n",
    "            Text = True\n",
    "        \n",
    "        #NAMES\n",
    "        if line[0:5] == \"\\\\f2\\\\b\":\n",
    "            if line[0:10] == \"\\\\f2\\\\b\\\\fs28\":\n",
    "                text_file.write('***'+text[idx].replace('\\\\', '').replace('f2bfs28 ','').replace('cf0 ', '').replace('cb1 ','')+'***'+'\\n')\n",
    "            else:\n",
    "                text_file.write('*'+text[idx].replace('\\\\', '').replace('f2b ','').replace('cf0 ', '').replace('cb1 ','')+'*'+'\\n')\n",
    "\n",
    "        ## CONSIGNES\n",
    "        if line[0:10] == \"\\\\f4\\\\i \\\\cf0\":\n",
    "            text_file.write('**'+text[idx].replace('\\\\', '').replace('f4i ','').replace('f4i', '').replace('cf0 ','')+'**'+'\\n')\n",
    "        idx += 1\n",
    "      \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For pursuit of hapiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters =  ['BARMAN', 'JESSICA', 'TREVOR', 'MARGARET', 'ALAN', 'PRIEST', 'MR CLEETHORPES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARM\n",
      "JESS\n",
      "TREV\n",
      "MARG\n",
      "ALAN\n",
      "PRIE\n",
      "MR C\n"
     ]
    }
   ],
   "source": [
    "characters_begin = [name[0:4] for name in characters]\n",
    "\n",
    "for i in characters_begin :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "# Open the RTF file for reading\n",
    "Name = False\n",
    "Text = False \n",
    "rtf_file_path = '/Users/hugo/Desktop/Projects/MSERT/scripts/not_processed/pursuit_of_happiness.rtf'\n",
    "with open(rtf_file_path, 'rb') as rtf_file:\n",
    "    # Use the striprtf library to convert RTF to plain text\n",
    "    rtf_text = rtf_file.read()\n",
    "    #convert bytes to string\n",
    "    rtf_text = rtf_text.decode('utf-8')\n",
    "\n",
    "    text_file_path = '/Users/hugo/Desktop/Projects/MSERT/scripts/processed/POH_processed.txt'\n",
    "    text_file = open(text_file_path, 'w')\n",
    "    idx = 0\n",
    "    #rtf_text = rtf_text.replace(\"b'{\\\\rtf1\\\\ansi\\\\ansicpg1252\\\\cocoartf2709\\n\\\\cocoatextscaling0\\\\cocoaplatform0{\\\\fonttbl\\\\f0\\\\fswiss\\\\fcharset0 Helvetica-Bold;\\\\f1\\\\fswiss\\\\fcharset0 Helvetica;\\\\f2\\\\froman\\\\fcharset0 Times-Bold;\\n\\\\f3\\\\froman\\\\fcharset0 Times-Roman;\\\\f4\\\\froman\\\\fcharset0 Times-Italic;}\\n{\\\\colortbl;\\\\red255\\\\green255\\\\blue255;\\\\red0\\\\green0\\\\blue0;\\\\red194\\\\green245\\\\blue244;\\\\red109\\\\green109\\\\blue109;\\n\\\\red0\\\\green0\\\\blue233;\\\\red255\\\\green255\\\\blue255;}\\n{\\\\*\\\\expandedcolortbl;;\\\\cssrgb\\\\c0\\\\c0\\\\c0;\\\\cssrgb\\\\c80000\\\\c96471\\\\c96471;\\\\cssrgb\\\\c50196\\\\c50196\\\\c50196;\\n\\\\cssrgb\\\\c0\\\\c0\\\\c93333;\\\\cssrgb\\\\c100000\\\\c100000\\\\c100000;}\\n\\\\paperw11900\\\\paperh16840\\\\margl1440\\\\margr1440\\\\vieww11520\\\\viewh8400\\\\viewkind0\\n\\\\deftab720\\n\\n\\\\itap1\\\\trowd \\\\taflags0 \\\\trgaph108\\\\trleft-108 \\\\trcbpat3 \\\\trwWidth15380\\\\trftsWidth3 \\\\trbrdrt\\\\brdrnil \\\\trbrdrl\\\\brdrnil \\\\trbrdrr\\\\brdrnil \\n\\\\clvertalc \\\\clshdrawnil \\\\clwWidth15260\\\\clftsWidth3 \\\\clmart10 \\\\clmarl10 \\\\clmarb10 \\\\clmarr10 \\\\clbrdrt\\\\brdrnil \\\\clbrdrl\\\\brdrnil \\\\clbrdrb\\\\brdrnil \\\\clbrdrr\\\\brdrnil \\\\clpadt20 \\\\clpadl20 \\\\clpadb20 \\\\clpadr20 \\\\gaph\\\\cellx8640\\n\\\\pard\\\\intbl\\\\itap1\\\\pardeftab720\\\\qc\\\\partightenfactor0\\n\\n\\\\f0\\\\b\\\\fs48 \\\\cf0 \\\\expnd0\\\\expndtw0\\\\kerning0\\n\\\\outl0\\\\strokewidth0 \\\\strokec2 The Tragedy of Hamlet, Prince of Denmark\\\\cell \\\\row\\n\\n\\\\itap1\\\\trowd \\\\taflags0 \\\\trgaph108\\\\trleft-108 \\\\trcbpat3 \\\\trwWidth15380\\\\trftsWidth3 \\\\trbrdrl\\\\brdrnil \\\\trbrdrt\\\\brdrnil \\\\trbrdrr\\\\brdrnil \\n\\\\clvertalc \\\\clshdrawnil \\\\clwWidth15260\\\\clftsWidth3 \\\\clmart10 \\\\clmarl10 \\\\clmarb10 \\\\clmarr10 \\\\clbrdrt\\\\brdrnil \\\\clbrdrl\\\\brdrnil \\\\clbrdrb\\\\brdrnil \\\\clbrdrr\\\\brdrnil \\\\clpadt20 \\\\clpadl20 \\\\clpadb20 \\\\clpadr20 \\\\gaph\\\\cellx8640\\n\\\\pard\\\\intbl\\\\itap1\\\\pardeftab720\\\\qc\\\\partightenfactor0\\n{\\\\field{\\\\*\\\\fldinst{HYPERLINK \"http://shakespeare.mit.edu/Shakespeare\"}}{\\\\fldrslt \\n\\\\f1\\\\b0\\\\fs24 \\\\cf5 \\\\ul \\\\ulc5 \\\\strokec5 Shakespeare homepage}}\\n\", '')\n",
    "    # Go throw the rtf_text (which is a string) and write each text line in a text file (if the text is between \\i and \\i0, add '**' at the beginning and end of the line)\n",
    "    text = rtf_text.split(\"\\n\")\n",
    "\n",
    "    italic = False\n",
    "    \n",
    "    for line in text:\n",
    "    \n",
    "        #TEXT\n",
    "        if line[0:4] in characters_begin and not italic :\n",
    "            \n",
    "            line = line.split(': ')\n",
    "\n",
    "            text_file.write('*'+line[0]+'*'+'\\n')  \n",
    "            if len(line[1].replace('\\\\','').replace('92','')) > 1 : \n",
    "                if line[1][0] == ' ' :\n",
    "                    text_file.write(line[1][1:].replace('\\\\','').replace('92','').replace('96','').replace(\"\\\\'85\",\"\")+'\\n')\n",
    "                else : \n",
    "                    text_file.write(line[1].replace('\\\\','').replace('92','').replace('96','').replace(\"'85\",\"\")+'\\n')    \n",
    "\n",
    "        if line[0:5] == '\\\\f2\\\\i' or line[0:5] == '\\\\f3\\\\i' :\n",
    "            italic = True \n",
    "            line = line[5:]\n",
    "\n",
    "        if line[0:6] == '\\\\f1\\\\i0' :\n",
    "            italic = False  \n",
    "\n",
    "            if line[12:16] in characters_begin :\n",
    "                line = line[12:].split(': ')\n",
    "                text_file.write('*'+line[0]+'*'+'\\n')\n",
    "                text_file.write(line[1].replace('\\\\','').replace('92','')+'\\n')\n",
    "            elif len(line[8:].replace('cf0 \\\\','').replace('\\\\','')) > 1 :\n",
    "                if line[7] != ' ' :\n",
    "                    text_file.write(line[7:].replace('\\\\','').replace('92','')+'\\n')\n",
    "                else : \n",
    "                    text_file.write(line[8:].replace('\\\\','').replace('92','')+'\\n')\n",
    "\n",
    "\n",
    "        if italic == True :\n",
    "            line_processed = line.replace(' \\\\cf0','').replace('\\\\cf0 ','').replace('\\\\pard\\\\pardeftab708\\\\ri380\\\\sl480\\\\slmult1\\\\qc\\\\partightenfactor0','').replace('\\\\f2\\\\b0 \\\\ulnone ','').replace(' \\\\ulc0 \\\\','').replace('\\\\f3\\\\b \\\\ul','').replace('\\\\pard\\\\pardeftab708\\\\ri380\\\\sl480\\\\slmult1\\\\partightenfactor0', '').replace('\\\\','').replace('92','')\n",
    "            #print(line_processed)\n",
    "            if len(line_processed) > 1 :\n",
    "                if line_processed[0] == ' ' :\n",
    "                    line_processed = line_processed[1:]\n",
    "                if line_processed[-1] == ' ' :\n",
    "                    line_processed = line_processed[:-1]\n",
    "                if len(line_processed.replace(' ','')) > 1 :\n",
    "                    text_file.write('**'+line_processed+'**'+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a csv file with predictions from BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/Desktop/Projects/MSERT/.env/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "\n",
    "\n",
    "def prediction(text, classifier = classifier):\n",
    "    preds = classifier(text)\n",
    "    #print(preds)\n",
    "    emotion = max(preds[0], key=lambda x:x['score'])\n",
    "\n",
    "    return emotion['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.92k/1.92k [00:00<00:00, 9.30MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 499M/499M [00:17<00:00, 28.7MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 380/380 [00:00<00:00, 1.56MB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 8.77MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 3.20MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 9.36MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 280/280 [00:00<00:00, 741kB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier_2 = pipeline(\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", return_all_scores=True)\n",
    "\n",
    "\n",
    "def prediction_2(text, classifier = classifier_2):\n",
    "    preds = classifier(text)\n",
    "    #print(preds)\n",
    "    emotion = max(preds[0], key=lambda x:x['score'])\n",
    "\n",
    "    return emotion['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.09k/1.09k [00:00<00:00, 2.85MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 329M/329M [00:11<00:00, 28.5MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 413/413 [00:00<00:00, 1.17MB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 3.48MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 38.6MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 5.16MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 280/280 [00:00<00:00, 1.13MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier_3 = pipeline(\"text-classification\", model=\"michellejieli/emotion_text_classifier\", return_all_scores=True)\n",
    "\n",
    "\n",
    "def prediction_3(text, classifier = classifier_3):\n",
    "    preds = classifier(text)\n",
    "    #print(preds)\n",
    "    emotion = max(preds[0], key=lambda x:x['score'])\n",
    "\n",
    "    return emotion['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1981/1981 [02:06<00:00, 15.62it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "preds = pd.DataFrame(columns = ['idx','type','character','sentence','j-hartmann/emotion-english-distilroberta-base','SamLowe/roberta-base-go_emotion', \"michellejieli/emotion_text_classifier\"])\n",
    "\n",
    "#Read throw a text file \n",
    "text_file_path = '/Users/hugo/Desktop/Projects/MSERT/scripts/processed/POH_processed.txt'\n",
    "text_file = open(text_file_path, 'r')\n",
    "text = text_file.readlines()\n",
    "with tqdm(total=len(text)) as pbar:\n",
    "    for line in text :\n",
    "        if line[0:2]=='**' :\n",
    "            preds.loc[len(preds)] = [len(preds), 'consigne', None, line[2:-3], None, None, None]\n",
    "        elif line[0]=='*' and line[1]!='*' :\n",
    "            name = line[1:-2]\n",
    "        elif line[0]!='*' :\n",
    "            #print(line)\n",
    "            line = re.split('(?<=[.!?]) +', line)\n",
    "            \n",
    "            for sentence in line :\n",
    "                if sentence != '\\n' : \n",
    "\n",
    "                    preds.loc[len(preds)] = [len(preds), 'speech', name, sentence, prediction(sentence, classifier), prediction_2(sentence), prediction_3(sentence)]\n",
    "      \n",
    "\n",
    "            \n",
    "        pbar.update(1)\n",
    "            # if len(line) > 1 :\n",
    "            #     for sentence in line :\n",
    "            #         if len(sentence) > 1 :\n",
    "            #             preds.loc[len(preds)] = [len(preds), 'speech', name, sentence+'.', None]\n",
    "            # else : \n",
    "            #preds.loc[len(preds)] = [len(preds), 'speech', name, line, None]\n",
    "\n",
    "preds.to_csv('/Users/hugo/Desktop/Projects/MSERT/scripts/processed/POH_processed.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'Hello ? Tu vas bien ? Oui ! ahah. Ca drvrait aller.'\n",
    "#Split tets into sentences for each punctuation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "nothing to repeat at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m re\u001b[39m.\u001b[39;49mfindall(\u001b[39m'\u001b[39;49m\u001b[39m?!.\u001b[39;49m\u001b[39m'\u001b[39;49m, test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/re/__init__.py:216\u001b[0m, in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfindall\u001b[39m(pattern, string, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    209\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[39m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \n\u001b[1;32m    215\u001b[0m \u001b[39m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39mfindall(string)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/re/__init__.py:294\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mas it is an undocumented flag \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mwithout an obvious purpose. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mDon\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt use it.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    293\u001b[0m               \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m--> 294\u001b[0m p \u001b[39m=\u001b[39m _compiler\u001b[39m.\u001b[39;49mcompile(pattern, flags)\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (flags \u001b[39m&\u001b[39m DEBUG):\n\u001b[1;32m    296\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_cache) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m _MAXCACHE:\n\u001b[1;32m    297\u001b[0m         \u001b[39m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/re/_compiler.py:743\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[39mif\u001b[39;00m isstring(p):\n\u001b[1;32m    742\u001b[0m     pattern \u001b[39m=\u001b[39m p\n\u001b[0;32m--> 743\u001b[0m     p \u001b[39m=\u001b[39m _parser\u001b[39m.\u001b[39;49mparse(p, flags)\n\u001b[1;32m    744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m     pattern \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/re/_parser.py:980\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    977\u001b[0m state\u001b[39m.\u001b[39mflags \u001b[39m=\u001b[39m flags\n\u001b[1;32m    978\u001b[0m state\u001b[39m.\u001b[39mstr \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\n\u001b[0;32m--> 980\u001b[0m p \u001b[39m=\u001b[39m _parse_sub(source, state, flags \u001b[39m&\u001b[39;49m SRE_FLAG_VERBOSE, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m    981\u001b[0m p\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mflags \u001b[39m=\u001b[39m fix_flags(\u001b[39mstr\u001b[39m, p\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mflags)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m source\u001b[39m.\u001b[39mnext \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/re/_parser.py:455\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    453\u001b[0m start \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mtell()\n\u001b[1;32m    454\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    456\u001b[0m                        \u001b[39mnot\u001b[39;49;00m nested \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m items))\n\u001b[1;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sourcematch(\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    458\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/re/_parser.py:682\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    680\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m item \u001b[39mor\u001b[39;00m item[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m AT:\n\u001b[0;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mnothing to repeat\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    683\u001b[0m                        source\u001b[39m.\u001b[39mtell() \u001b[39m-\u001b[39m here \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(this))\n\u001b[1;32m    684\u001b[0m \u001b[39mif\u001b[39;00m item[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m _REPEATCODES:\n\u001b[1;32m    685\u001b[0m     \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mmultiple repeat\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    686\u001b[0m                        source\u001b[39m.\u001b[39mtell() \u001b[39m-\u001b[39m here \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(this))\n",
      "\u001b[0;31merror\u001b[0m: nothing to repeat at position 0"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "re.findall('?!.', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello ?', 'Tu vas bien ?', 'Oui !', 'ahah.', 'Ca drvrait aller.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n",
    "#Split the sentence on the punctuation keeping the punctuation\n",
    "re.split('(?<=[.!?]) +', test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
